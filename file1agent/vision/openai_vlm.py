"""
OpenAI implementation of Visual Language Model (VLM).
"""

from typing import Any, Dict, List, Callable
from loguru import logger
import openai

from .base_vlm import BaseVLM
from ..config import ModelConfig

base64_prefix_png = "data:image/png;base64,"
MSG_FORMATTERS = [
    # Formatter A: Standard OpenAI format
    lambda p, img: [
        {
            "role": "user",
            "content": [{"type": "text", "text": p}, {"type": "image_url", "image_url": {"url": img if img.startswith("data:") else base64_prefix_png + img}}],
        }
    ],
    # # Formatter B: Alternative format for some models
    # lambda p, img: [
    #     {
    #         "role": "user",
    #         "content": [
    #             {"type": "text", "text": p},
    #             {"type": "image", "source_type": "base64", "data": img, "mime_type": "image/jpeg"},
    #         ],
    #     }
    # ],
]


class OpenAIVLM(BaseVLM):
    """
    OpenAI implementation of Visual Language Model.
    """

    def __init__(self, config: ModelConfig):
        """
        Initialize the OpenAI client.
        """
        super().__init__(config)
        self.client = openai.OpenAI(api_key=self.api_key, base_url=self.base_url)

    def _call_model(self, message: List[Dict[str, Any]]) -> str:
        """
        Call the OpenAI model with the formatted message.

        Args:
            message: Formatted message for OpenAI's API

        Returns:
            Model response text
        """
        response = self.client.chat.completions.create(model=self.model, messages=message)

        return response.choices[0].message.content

    def call_vlm(self, image_base64: str, prompt: str, max_retries: int = 3) -> str:
        """
        Override the base method to try different message formats.

        Args:
            image_base64: Base64 encoded image data
            prompt: Prompt text
            max_retries: Maximum number of retries on failure

        Returns:
            VLM response content
        """

        error_msg = ""
        for attempt in range(max_retries):
            for formatter in MSG_FORMATTERS:
                try:
                    # Format the message for the specific VLM API
                    message = formatter(prompt, image_base64)

                    # Call the VLM model
                    response = self._call_model(message)

                    logger.info(f"Vision response: {response.replace('\n', ' ')}")
                    return response
                except Exception as e:
                    error_msg = f"Error when calling VLM: {e}"[:1000]
                    logger.warning(error_msg)
                    logger.warning("Retrying with different formatter...")
                    import time

                    time.sleep(5)

        return error_msg


if __name__ == "__main__":

    vlm = OpenAIVLM(ModelConfig(model="free-vision", base_url="http://127.0.0.1:8077/v1", api_key="0"))
    image_base64 = "data:image/png;base64,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"

    prompt = "What is the main topic of this image?"
    response = vlm.call_vlm(image_base64, prompt)
    print(response)
